{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# url is http://www.foodandwaterwatch.org/sites/default/files/water_rate_survey-location_0.pdf\n",
    "# downloaded pdf, converted to csv, cleaned up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create directory\n",
    "path = 'data/pricing/pricing.csv'\n",
    "df = pd.read_csv(path)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_lat_lng(address):\n",
    "    # 1) Set-up service url:\n",
    "    import urllib\n",
    "    import json\n",
    "\n",
    "    # Google URL\n",
    "    serviceurl = \"https://maps.googleapis.com/maps/api/geocode/json?\"\n",
    "    api_key = 'your_api_key'\n",
    "\n",
    "    # 2) Encode location data into 'url-speak' to be added to the end of the service url\n",
    "    url = serviceurl + urllib.urlencode({'sensor':'false', 'address': address}) +'&key=' + api_key\n",
    "\n",
    "    # 3) Open the socket to the url\n",
    "    socket = urllib.urlopen(url)\n",
    "\n",
    "    # 4) Read th data in as a string.\n",
    "    data_string = socket.read()\n",
    "\n",
    "    # 5) Convert it from a JSON string to a dictionary\n",
    "    data_dict = json.loads(data_string)\n",
    "\n",
    "    return data_dict[\"results\"][0][\"geometry\"][\"location\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def df_to_list(dataframe, col1, col2):\n",
    "    # extract columns from dataframe\n",
    "    l_extract = dataframe[[col1, col2]].values.tolist()\n",
    "    l_extract2 = []\n",
    "    \n",
    "    # concatenate each nested element into a comma-delimited string, append to new list\n",
    "    for elements in l_extract:\n",
    "        text = elements[0] + ', ' + elements[1]\n",
    "        l_extract2.append(text)\n",
    "    return l_extract2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def geo_list(place_state_list):\n",
    "    return_list = []\n",
    "    for place_state in place_state_list:\n",
    "        try:\n",
    "            geo_dict = get_lat_lng(place_state)\n",
    "            split = place_state.rpartition(',')\n",
    "            loc = split[0]\n",
    "            state = split[2].strip()\n",
    "            tuple_output = (loc, state, geo_dict['lng'], geo_dict['lat'])\n",
    "            return_list.append(tuple_output)\n",
    "            print place_state, geo_dict['lng'], geo_dict['lat']\n",
    "        except:\n",
    "            tuple_output = (place_state, 'none', 'none')\n",
    "            return_list.append(tuple_output)\n",
    "            print 'no geocode'\n",
    "    return return_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "utility_locations = df_to_list(df, 'System', 'State')\n",
    "utility_locations[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "geocoded = geo_list(utility_locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_geo = pd.DataFrame(geocoded)\n",
    "df_geo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# drop columns, rename remaining columns\n",
    "df_geo.drop([0,1], axis=1, inplace=True)\n",
    "df_geo.rename(columns={2:'lng', 3:'lat'}, inplace=True)\n",
    "df_geo.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# merge, rename cols, drop other cols\n",
    "df_joined = df.join(df_geo, how='inner')\n",
    "df_joined.rename(columns={'System':'system', 'Annual Bill':'bill', 'State':'state', 'Owner':'owner'}, inplace=True)\n",
    "df_joined.drop(['Utility','System_Old'], axis=1, inplace=True)\n",
    "df_joined.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# filter out none lons and lats and take non-nans\n",
    "\n",
    "df_joined['lng'] = pd.to_numeric(df_joined['lng'], errors='coerce')\n",
    "df_joined['lat'] = pd.to_numeric(df_joined['lat'], errors='coerce')\n",
    "df_joined = df_joined[np.isfinite(df_joined['lng'])]\n",
    "print df_joined.dtypes, df_joined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_joined.to_csv('data/pricing/geocoded.csv')\n",
    "import pickle\n",
    "with open('data/pricing/geocoded.pickle', 'wb') as f:\n",
    "    pickle.dump(df_joined, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
