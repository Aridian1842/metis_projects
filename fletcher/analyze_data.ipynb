{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>nyt_id</th>\n",
       "      <th>org</th>\n",
       "      <th>hl</th>\n",
       "      <th>lead</th>\n",
       "      <th>date_pub</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>4fc0a09745c1498b0d3ba216</td>\n",
       "      <td>none</td>\n",
       "      <td>MARIJUANA SMOKING IS REPORTED SAFE Hemp Leaves...</td>\n",
       "      <td>PANAMA Nov 14  A Panaman Judge recently senten...</td>\n",
       "      <td>1926-11-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>4fc1d8e345c1498b0d4ccb9f</td>\n",
       "      <td>none</td>\n",
       "      <td>USE OF MARIJUANA SPREADING IN WEST Poisonous W...</td>\n",
       "      <td>DENVER Sept 13  Although as appalling in its e...</td>\n",
       "      <td>1934-09-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>4fc1ebab45c1498b0d528e5b</td>\n",
       "      <td>The Associated Press</td>\n",
       "      <td>RHODE ISLAND TO END WEED AS DRUG SOURCE State ...</td>\n",
       "      <td>PROVIDENCE RI Jan 19 Rhode Island authorities ...</td>\n",
       "      <td>1935-01-20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                    nyt_id                   org  \\\n",
       "0      3  4fc0a09745c1498b0d3ba216                  none   \n",
       "1      9  4fc1d8e345c1498b0d4ccb9f                  none   \n",
       "2     12  4fc1ebab45c1498b0d528e5b  The Associated Press   \n",
       "\n",
       "                                                  hl  \\\n",
       "0  MARIJUANA SMOKING IS REPORTED SAFE Hemp Leaves...   \n",
       "1  USE OF MARIJUANA SPREADING IN WEST Poisonous W...   \n",
       "2  RHODE ISLAND TO END WEED AS DRUG SOURCE State ...   \n",
       "\n",
       "                                                lead   date_pub  \n",
       "0  PANAMA Nov 14  A Panaman Judge recently senten... 1926-11-21  \n",
       "1  DENVER Sept 13  Although as appalling in its e... 1934-09-16  \n",
       "2  PROVIDENCE RI Jan 19 Rhode Island authorities ... 1935-01-20  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle('data/re_merge/clean.pickle')\n",
    "df.reset_index(inplace=True)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['PANAMA Nov 14  A Panaman Judge recently sentenced an American seaman Hamilton Main to a year of penal confinement for smoking and having in his possession cigarettes made of the leaves of the cannabis indica known also as marijuana canjac and by various other names and often incorrectly referred to as hashish'],\n",
       " ['DENVER Sept 13  Although as appalling in its effects on the human mind and body as narcotics the consumption of marijuana appears to be proceeding virtually unchecked in Colorado and other Western States with a large SpanishAmerican population'],\n",
       " ['PROVIDENCE RI Jan 19 Rhode Island authorities are planning a Spring drive to eradicate the marijuana or Mexico weed which long has been the source of large supplies of the dangerous narcotic drug known as hashish'],\n",
       " ['To enable policemen to familiarize themselves with the appearance of marijuana pots of the narcotic weed have been placed on exhibition during the past few days in the assembly rooms of station houses in various sections of Brooklyn'],\n",
       " ['Three million dollars worth  at bootleg prices  of marijuana weed which is used in cigarette form as a narcotic was burned in a vacant lot in Brooklyn yesterday in the presence of Police Commissioner Valentine Captain Joseph Mooney of the narcotic squad and other police officials']]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "li = df[['lead']].head().values.tolist()\n",
    "li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'PANAMA',\n",
       " u'Nov',\n",
       " u'14',\n",
       " u'A',\n",
       " u'Panaman',\n",
       " u'Judg',\n",
       " u'recent',\n",
       " u'sentenc',\n",
       " u'an',\n",
       " u'American',\n",
       " u'seaman',\n",
       " u'Hamilton',\n",
       " u'Main',\n",
       " u'to',\n",
       " u'a',\n",
       " u'year',\n",
       " u'of',\n",
       " u'penal',\n",
       " u'confin',\n",
       " u'for',\n",
       " u'smoke',\n",
       " u'and',\n",
       " u'have',\n",
       " u'in',\n",
       " u'hi',\n",
       " u'possess',\n",
       " u'cigarett',\n",
       " u'made',\n",
       " u'of',\n",
       " u'the',\n",
       " u'leav',\n",
       " u'of',\n",
       " u'the',\n",
       " u'cannabi',\n",
       " u'indica',\n",
       " u'known',\n",
       " u'also',\n",
       " u'as',\n",
       " u'marijuana',\n",
       " u'canjac',\n",
       " u'and',\n",
       " u'by',\n",
       " u'variou',\n",
       " u'other',\n",
       " u'name',\n",
       " u'and',\n",
       " u'often',\n",
       " u'incorrectli',\n",
       " u'refer',\n",
       " u'to',\n",
       " u'as',\n",
       " u'hashish']"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stem words and tokenize\n",
    "\n",
    "stemmer = nltk.stem.porter.PorterStemmer()\n",
    "li_stem = []\n",
    "for article in li:\n",
    "    article_temp = []\n",
    "    for string in article:\n",
    "        for word in TextBlob(string).words:\n",
    "            article_temp.append(stemmer.stem(word))\n",
    "    li_stem.append(article_temp)\n",
    "li_stem[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'PANAMA',\n",
       " u'Nov',\n",
       " u'14',\n",
       " u'A',\n",
       " u'Panaman',\n",
       " u'Judg',\n",
       " u'recent',\n",
       " u'sentenc',\n",
       " u'American',\n",
       " u'seaman',\n",
       " u'Hamilton',\n",
       " u'Main',\n",
       " u'year',\n",
       " u'penal',\n",
       " u'confin',\n",
       " u'smoke',\n",
       " u'hi',\n",
       " u'possess',\n",
       " u'cigarett',\n",
       " u'made',\n",
       " u'leav',\n",
       " u'cannabi',\n",
       " u'indica',\n",
       " u'known',\n",
       " u'also',\n",
       " u'marijuana',\n",
       " u'canjac',\n",
       " u'variou',\n",
       " u'name',\n",
       " u'often',\n",
       " u'incorrectli',\n",
       " u'refer',\n",
       " u'hashish']"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove stopwords\n",
    "from nltk.corpus import stopwords\n",
    "li_sw = []\n",
    "for article in li_stem:\n",
    "    filtered_words = [word for word in article if word not in stopwords.words('english')]\n",
    "    li_sw.append(filtered_words)\n",
    "li_sw[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'PANAMA Nov 14 A Panaman Judg recent sentenc American seaman Hamilton Main year penal confin smoke hi possess cigarett made leav cannabi indica known also marijuana canjac variou name often incorrectli refer hashish',\n",
       " u'DENVER Sept 13 Although appal effect human mind bodi narcot consumpt marijuana appear proceed virtual uncheck Colorado Western State larg SpanishAmerican popul',\n",
       " u'PROVID RI Jan 19 Rhode Island author plan Spring drive erad marijuana Mexico weed long ha sourc larg suppli danger narcot drug known hashish',\n",
       " u'To enabl policemen familiar themselv appear marijuana pot narcot weed place exhibit dure past day assembl room station hous variou section Brooklyn',\n",
       " u'Three million dollar worth bootleg price marijuana weed use cigarett form narcot wa burn vacant lot Brooklyn yesterday presenc Polic Commission Valentin Captain Joseph Mooney narcot squad polic offici']"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# join words\n",
    "documents = []\n",
    "for article in li_sw:\n",
    "    documents.append(' '.join(article))\n",
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get bigrams\n",
    "from nltk.util import ngrams\n",
    "from collections import defaultdict\n",
    "from operator import itemgetter\n",
    "import copy\n",
    "from collections import defaultdict\n",
    "\n",
    "documents = copy.deepcopy(li_sw)\n",
    "\n",
    "counter = defaultdict(int)\n",
    "\n",
    "n = 2\n",
    "for doc in documents:\n",
    "    bigrams = ngrams(doc, n)\n",
    "    for gram in bigrams:\n",
    "        counter[gram] += 1\n",
    "\n",
    "for gram, count in sorted(counter.items(), key = itemgetter(1), reverse=True)[:30]:\n",
    "    phrase = \" \".join(gram)\n",
    "    #print '%20s %i' % (phrase, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'above', u'above all', u'all', u'all to', u'be', u'be true', u'come', u'come to', u'denmark', u'in', u'in the', u'is', u'is rotten', u'is should', u'of', u'of denmark', u'own', u'own self', u'rotten', u'rotten in', u'self', u'self be', u'should', u'should come', u'something', u'something is', u'state', u'state of', u'that', u'that is', u'the', u'the state', u'thine', u'thine own', u'this', u'this above', u'to', u'to thine', u'to this', u'true']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "text = ['That is should come to this!', 'This above all: to thine own self be true.', 'Something is rotten in the state of Denmark.']\n",
    "\n",
    "#CountVectorizer is a class; so `vectorizer` below represents an instance of that object.\n",
    "vectorizer = CountVectorizer(ngram_range=(1,2))\n",
    "\n",
    "# call `fit` to build the vocabulary\n",
    "vectorizer.fit(text)\n",
    "\n",
    "# then, use `get_feature_names` to return the tokens\n",
    "print vectorizer.get_feature_names()\n",
    "\n",
    "# finally, call `transform` to convert text to a bag of words\n",
    "x = vectorizer.transform(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparse Matrix\n",
      "  (0, 6)\t1\n",
      "  (0, 7)\t1\n",
      "  (0, 11)\t1\n",
      "  (0, 13)\t1\n",
      "  (0, 22)\t1\n",
      "  (0, 23)\t1\n",
      "  (0, 28)\t1\n",
      "  (0, 29)\t1\n",
      "  (0, 34)\t1\n",
      "  (0, 36)\t1\n",
      "  (0, 38)\t1\n",
      "  (1, 0)\t1\n",
      "  (1, 1)\t1\n",
      "  (1, 2)\t1\n",
      "  (1, 3)\t1\n",
      "  (1, 4)\t1\n",
      "  (1, 5)\t1\n",
      "  (1, 16)\t1\n",
      "  (1, 17)\t1\n",
      "  (1, 20)\t1\n",
      "  (1, 21)\t1\n",
      "  (1, 32)\t1\n",
      "  (1, 33)\t1\n",
      "  (1, 34)\t1\n",
      "  (1, 35)\t1\n",
      "  (1, 36)\t1\n",
      "  (1, 37)\t1\n",
      "  (1, 39)\t1\n",
      "  (2, 8)\t1\n",
      "  (2, 9)\t1\n",
      "  (2, 10)\t1\n",
      "  (2, 11)\t1\n",
      "  (2, 12)\t1\n",
      "  (2, 14)\t1\n",
      "  (2, 15)\t1\n",
      "  (2, 18)\t1\n",
      "  (2, 19)\t1\n",
      "  (2, 24)\t1\n",
      "  (2, 25)\t1\n",
      "  (2, 26)\t1\n",
      "  (2, 27)\t1\n",
      "  (2, 30)\t1\n",
      "  (2, 31)\t1\n",
      "<class 'scipy.sparse.csr.csr_matrix'>\n",
      "\n",
      "Matrix\n",
      "<type 'numpy.ndarray'>\n",
      "[[0 0 0 0 0 0 1 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 1 0 0 0 0 1 0 1\n",
      "  0 1 0]\n",
      " [1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1\n",
      "  1 0 1]\n",
      " [0 0 0 0 0 0 0 0 1 1 1 1 1 0 1 1 0 0 1 1 0 0 0 0 1 1 1 1 0 0 1 1 0 0 0 0 0\n",
      "  0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print 'Sparse Matrix'\n",
    "print x # A compressed version; the \"sparse\" matrix.\n",
    "print type(x) \n",
    "print\n",
    "print 'Matrix'\n",
    "x_back = x.toarray()\n",
    "print type(x_back)\n",
    "print x_back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
